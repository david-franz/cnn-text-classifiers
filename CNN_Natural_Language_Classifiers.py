# -*- coding: utf-8 -*-
"""lecture-CNN-without-pretrained-embedding.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1u8LvZOSymDyhpYeQ2V_k3Lqh6MNxWXII
"""

import pandas
data = pandas.read_csv("simple-review.csv", encoding="latin-1")
data

from sklearn import model_selection, preprocessing, metrics
# split the dataset into training and validation datasets
train_x, test_x, train_y, test_y = model_selection.train_test_split(data['text'], data['label'], shuffle=False)

# label encode the target variable
encoder = preprocessing.LabelEncoder()
train_y = encoder.fit_transform(train_y)
test_y = encoder.fit_transform(test_y)
print(train_x[0:10])
print(train_y[0:10])

# word to integer IDs, documents padded to the same length

import numpy
from tensorflow.keras.preprocessing import text, sequence

# create a tokenizer
token = text.Tokenizer()
token.fit_on_texts(data['text'])
word_index = token.word_index

# convert text to sequence of tokens and pad them to ensure equal length vectors
train_seq_x = sequence.pad_sequences(token.texts_to_sequences(train_x), maxlen=70)
test_seq_x = sequence.pad_sequences(token.texts_to_sequences(test_x), maxlen=70)
train_seq_x[0]

# CNN parameters from https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/keras/basic_text_classification.ipynb

#not use any pre-trained embedding
from keras.models import Sequential
from keras import layers

vocab_size = len(word_index)+1
maxlen = 70

model = Sequential()
model.add(layers.Embedding(input_dim=vocab_size, output_dim=50, input_length=maxlen))
model.build((None, maxlen)) # build the Embedding to inilizices the weight
model.add(layers.Conv1D(filters=128, kernel_size=5, activation='relu'))

model.add(layers.GlobalAveragePooling1D())
model.add(layers.Dense(16, activation='relu'))
model.add(layers.Dense(1, activation='sigmoid'))

model.summary()

model.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['acc'])

history = model.fit(train_seq_x,
                    train_y,
                    epochs=10,
                    batch_size=512,
                    validation_data=(test_seq_x, test_y),
                    verbose=1)
results = model.evaluate(test_seq_x, test_y)

print(results)
